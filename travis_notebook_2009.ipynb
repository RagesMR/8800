{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "#### To use this method, two files have to be saved in this direction: \n",
    "\n",
    "##### 1) Question Raw Data, named YYYYData.xls.  The \"Report\" sheet at the end MUST BE DELETED\n",
    "##### 2) All Students, named YYYYStudents.xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(year):\n",
    "    directory = './'+str(year)+'Data.xls'\n",
    "    \n",
    "    \n",
    "    overallDF = pd.DataFrame()\n",
    "    book = xlrd.open_workbook(directory) \n",
    "    num_sheets = len(book.sheets())\n",
    "\n",
    "    sheet_names = book.sheet_names()\n",
    "    sheet_names\n",
    "\n",
    "    #GET ALL STUDENTS TO USE AS THE INDEX\n",
    "    book_students = xlrd.open_workbook('./'+ str(year) + 'Students.xlsx')\n",
    "    all_students = pd.read_excel('./'+ str(year) + 'Students.xlsx', 'Sheet1', header=None).iloc[:,0].tolist()\n",
    "    \n",
    "    possiblePoints = pd.Series() #creating a separate DF for possible points\n",
    "    \n",
    "    for i in range(num_sheets):\n",
    "        this_sheet = sheet_names[i]\n",
    "        if (this_sheet == \"Carol Whitman - 03-SPIKES Proto\"):\n",
    "            continue ## HACK TO SKIP A SHEET THAT HAS IDENTICAL COLUMNS TO ANOTHER SHEET\n",
    "        df = pd.read_excel(directory, this_sheet)\n",
    "        df.set_index(df.columns[0], inplace=True)\n",
    "        \n",
    "        possible_points_case = df.iloc[0]\n",
    "        possiblePoints = possiblePoints.append(possible_points_case)\n",
    "        \n",
    "        df = df.reindex(all_students) #somewhere around here is where you decide what to do with NaN values\n",
    "        df = df.reset_index()\n",
    "        overallDF = pd.concat([overallDF, df], axis=1)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    return overallDF, possiblePoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_ID = pd.read_excel('./AllStudentsWithNumbers.xlsx', 'Sheet1')\n",
    "\n",
    "ID_Score = pd.read_excel('./CSResults.xlsx', '2008-2014')\n",
    "\n",
    "name_ID_score = pd.merge(name_ID, ID_Score, on=['Identifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Mean and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize values by dividing by possible points for that question, then compute row-wise mean and variance for those selected columns and add to end of DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mean_var_for_year(yearDF, year_dict, possible_points):\n",
    "    def construct_full_q(q, form_name, case_name):\n",
    "        return q + \"_\" + form_name + \"_SP_\" + case_name\n",
    "    \n",
    "    new_year_df = pd.DataFrame()\n",
    "    new_year_df[\"StudentName\"] = yearDF.iloc[:,0]\n",
    "    \n",
    "    for form_name, sub_cat_dict in year_dict.iteritems():\n",
    "        for sub_cat, case_dict in sub_cat_dict.iteritems():\n",
    "            all_questions_for_sub_cat = []\n",
    "            all_poss_points_for_sub_cat = pd.Series()\n",
    "            for case, questions in case_dict.iteritems():\n",
    "                col_names = [construct_full_q(q, form_name, case) for q in questions]\n",
    "                selected_cols = list(yearDF.loc[:, yearDF.columns.str.contains(('|'.join(col_names)))].columns)\n",
    "#                 if (case == 'AMBN'):\n",
    "#                     print(\"Questions: \")\n",
    "#                     print(questions)\n",
    "#                     print(\"Column Names For Query:\")\n",
    "#                     print(col_names)\n",
    "#                     print(\"Columns Selected:\")\n",
    "#                     print(selected_cols)\n",
    "#                 print(all_questions_for_sub_cat)\n",
    "                all_questions_for_sub_cat = all_questions_for_sub_cat + selected_cols\n",
    "#                 print(all_questions_for_sub_cat)\n",
    "                selected_points = possible_points[col_names]\n",
    "                all_poss_points_for_sub_cat = all_poss_points_for_sub_cat.append(selected_points) \n",
    "    \n",
    "            new_year_df[\"mean_\" + form_name + \"_\" + sub_cat] = yearDF[all_questions_for_sub_cat].div(all_poss_points_for_sub_cat).mean(axis=1)\n",
    "            new_year_df[\"var_\" + form_name + \"_\" + sub_cat] = yearDF[all_questions_for_sub_cat].div(all_poss_points_for_sub_cat).var(axis=1)\n",
    "    \n",
    "    return new_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper method to generate list of strings based on start and end question numbers\n",
    "def generate_question_strings(first_q, last_q):\n",
    "    def question_string(num):\n",
    "        return \"Q\" + str(num)\n",
    "    int_list = list(range(first_q,last_q+1))\n",
    "    return [question_string(num) for num in int_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deidentify_and_add_scores(year_DF, year):\n",
    "    named_ID_score_year = name_ID_score[name_ID_score.Year_x == year]\n",
    "\n",
    "    with_scores = pd.merge(year_DF, named_ID_score_year, left_on = 'StudentName', right_on = 'Student Name')\n",
    "\n",
    "    final_df = with_scores.drop(['StudentName', 'Student Name', 'Year_y'], axis=1)\n",
    "    \n",
    "    ## Move Identifier Column and year to the front of the DF, then rename\n",
    "    cols = list(final_df)\n",
    "    cols.insert(0, cols.pop(cols.index('Identifier')))\n",
    "    cols.insert(1, cols.pop(cols.index('Year_x')))\n",
    "    final_df = final_df.ix[:, cols]\n",
    "    \n",
    "    #Rename some columns\n",
    "    final_df = final_df.rename(index=str, columns={\"Identifier\": \"ID\", \"Year_x\": \"Year\"})\n",
    "    \n",
    "    #Transform scores\n",
    "    final_df['P/F'] = final_df['P/F'].map({'P':1,'F':0})\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_clean_year_data(year, year_dict):\n",
    "    print(\"loading \" + str(year) + \" excel sheet....\")\n",
    "    overalldf, possible_points = load_data(year)\n",
    "    \n",
    "    seen = {}\n",
    "    dupes = []\n",
    "\n",
    "    for x in overalldf.columns:\n",
    "        if x not in seen:\n",
    "            seen[x] = 1\n",
    "        else:\n",
    "            if seen[x] == 1:\n",
    "                dupes.append(x)\n",
    "            seen[x] += 1\n",
    "    print(dupes)\n",
    "    \n",
    "    print(\"Calculating Mean and Variance of Question Groups...\")\n",
    "    modified = get_mean_var_for_year(overalldf, year_dict, possible_points)\n",
    "    \n",
    "    print(\"Deidentifying and adding scores...\")\n",
    "    final_year_df = deidentify_and_add_scores(modified, year)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return final_year_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_2009 = {\n",
    "    'PPI': {\n",
    "        'init': {\n",
    "            'AP': generate_question_strings(1,4), #Marty Elliot\n",
    "            'TW': generate_question_strings(1,4), #Alex Miller\n",
    "            'AMBN': generate_question_strings(1,4), #Carol Whitman\n",
    "            'WL': generate_question_strings(1,4), #Corey Wolfe\n",
    "            'SOB': generate_question_strings(1,4), #Dana Mitchell\n",
    "            'H': generate_question_strings(1,3),  #Jamie Browning\n",
    "            'CP': generate_question_strings(1,4), #Leslie Keats\n",
    "            'CS': generate_question_strings(1,4), #Sam Swift/Grandparent\n",
    "            'KP': generate_question_strings(1,4), #Shawn Clancy\n",
    "            'LAP': generate_question_strings(1,4) #Tessa Frost\n",
    "        },\n",
    "        'info_gather': {\n",
    "            'AP': generate_question_strings(5,12),\n",
    "            'TW': generate_question_strings(5,12),\n",
    "            'AMBN': generate_question_strings(5,12),\n",
    "            'WL': generate_question_strings(5,12),\n",
    "            'SOB': generate_question_strings(5,12),\n",
    "            'H': generate_question_strings(4,11),\n",
    "            'CP': generate_question_strings(5,12),\n",
    "            'CS': generate_question_strings(5,12),\n",
    "            'KP': generate_question_strings(5,12),\n",
    "            'LAP': generate_question_strings(5,12) \n",
    "        },\n",
    "        'closing': {\n",
    "            'AP': generate_question_strings(13,16),\n",
    "            'TW': generate_question_strings(13,16),\n",
    "            'AMBN': generate_question_strings(13,16),\n",
    "            'WL': generate_question_strings(13,16),\n",
    "            'SOB': generate_question_strings(13,16),\n",
    "            'H': generate_question_strings(12,15),\n",
    "            'CP': generate_question_strings(13,16),\n",
    "            'CS': generate_question_strings(13,16),\n",
    "            'KP': generate_question_strings(13,16),\n",
    "            'LAP': generate_question_strings(13,16)\n",
    "        }\n",
    "    },\n",
    "    'Hx': {\n",
    "        'history': {\n",
    "            'AP': generate_question_strings(1,9),\n",
    "            'TW': generate_question_strings(1,13),\n",
    "            'AMBN': generate_question_strings(1,6),\n",
    "            'WL': generate_question_strings(1,9),\n",
    "            'SOB': generate_question_strings(1,14),\n",
    "            'H': generate_question_strings(1,11),\n",
    "            'CP': generate_question_strings(1,14),\n",
    "            'CS': generate_question_strings(1,11),\n",
    "            'KP': generate_question_strings(1,9),\n",
    "            'LAP': generate_question_strings(1,15)\n",
    "        }\n",
    "    },\n",
    "    'PE': { #Carol Whitman did not do PE\n",
    "        'handwash': {\n",
    "            'AP': generate_question_strings(1,1),\n",
    "            'TW': generate_question_strings(1,1),\n",
    "            'WL': generate_question_strings(1,1),\n",
    "            'SOB': generate_question_strings(1,1),\n",
    "            'H': generate_question_strings(1,1),\n",
    "            'CP': generate_question_strings(1,1),\n",
    "            'CS': generate_question_strings(1,1),\n",
    "            'KP': generate_question_strings(1,1),\n",
    "            'LAP': generate_question_strings(1,1)\n",
    "        },\n",
    "        'phys_check': {\n",
    "            'AP': generate_question_strings(2,2) + generate_question_strings(4,9),\n",
    "            'TW': generate_question_strings(2,2) + generate_question_strings(4,20),\n",
    "            'WL': generate_question_strings(2,2) + generate_question_strings(4,10),\n",
    "            'SOB': generate_question_strings(2,2) + generate_question_strings(4,6),\n",
    "            'H': generate_question_strings(2,2) + generate_question_strings(4,21),\n",
    "            'CP': generate_question_strings(2,2) + generate_question_strings(4,10),\n",
    "            'CS': generate_question_strings(2,2) + generate_question_strings(4,13),\n",
    "            'KP': generate_question_strings(2,2) + generate_question_strings(4,8),\n",
    "            'LAP': generate_question_strings(2,2) + generate_question_strings(3,7)\n",
    "        },\n",
    "        'modesty': {\n",
    "            'AP': generate_question_strings(3,3),\n",
    "            'TW': generate_question_strings(3,3),\n",
    "            'WL': generate_question_strings(3,3),\n",
    "            'SOB': generate_question_strings(3,3),\n",
    "            'H': generate_question_strings(3,3),\n",
    "            'CP': generate_question_strings(3,3),\n",
    "            'CS': generate_question_strings(3,3),\n",
    "            'KP': generate_question_strings(3,3),\n",
    "            'LAP': generate_question_strings(3,3)\n",
    "        }\n",
    "    },\n",
    "    'PS': {\n",
    "        'personal': {\n",
    "            'AP': generate_question_strings(1,1),\n",
    "            'TW': generate_question_strings(1,1),\n",
    "            'AMBN': generate_question_strings(1,1),\n",
    "            'WL': generate_question_strings(1,1),\n",
    "            'SOB': generate_question_strings(1,1),\n",
    "            'H': generate_question_strings(1,1),\n",
    "            'CP': generate_question_strings(1,1),\n",
    "            'CS': generate_question_strings(1,1),\n",
    "            'KP': generate_question_strings(1,1),\n",
    "            'LAP': generate_question_strings(1,1)\n",
    "        },\n",
    "        'rec': {\n",
    "            'AP': generate_question_strings(2,2),\n",
    "            'TW': generate_question_strings(2,2),\n",
    "            'AMBN': generate_question_strings(2,2),\n",
    "            'WL': generate_question_strings(2,2),\n",
    "            'SOB': generate_question_strings(2,2),\n",
    "            'H': generate_question_strings(2,2),\n",
    "            'CP': generate_question_strings(2,2),\n",
    "            'CS': generate_question_strings(2,2),\n",
    "            'KP': generate_question_strings(2,2),\n",
    "            'LAP': generate_question_strings(1,1)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 2009 excel sheet....\n",
      "Alex Miller - 02-ACIR\n",
      "Alex Miller - 05-Patient Satisf\n",
      "Alex Miller - 01-Patient-Physic\n",
      "Alex Miller - Patient Note Scor\n",
      "Alex Miller - 04-Physical Exam \n",
      "Alex Miller - 03-History Alex M\n",
      "Carol Whitman - 04-Patient Sati\n",
      "Carol Whitman - 01-Patient-Phys\n",
      "Carol Whitman - 03-SPIKES Proto\n",
      "Carol Whitman - 02-History Caro\n",
      "Corey Wolfe - 05-Patient Satisf\n",
      "Corey Wolfe - 01-Patient-Physic\n",
      "Corey Wolfe - 02-ACIR\n",
      "Corey Wolfe - Patient Note Scor\n",
      "Corey Wolfe - 04-Physical Exam \n",
      "Corey Wolfe - 03-History Corey \n",
      "Dana Mitchell - 05-Patient Sati\n",
      "Dana Mitchell - 01-Patient-Phys\n",
      "Dana Mitchell - 02-ACIR\n",
      "Dana Mitchell - Patient Note Sc\n",
      "Dana Mitchell - 04-Physical Exa\n",
      "Dana Mitchell - 03-History Dana\n",
      "Jamie Browning - 05-Patient Sat\n",
      "Jamie Browning - 01-Patient-Phy\n",
      "Jamie Browning - 02-ACIR\n",
      "Jamie Browning - Patient Note S\n",
      "Jamie Browning - 03-History Jam\n",
      "Jamie Browning - 04-Physical Ex\n",
      "Leslie Keats - 05-Patient Satis\n",
      "Leslie Keats - 01-Patient-Physi\n",
      "Leslie Keats - 02-ACIR\n",
      "Leslie Keats - Patient Note Sco\n",
      "Leslie Keats - 04-Physical Exam\n",
      "Leslie Keats - 03-History Lesli\n",
      "Marty Elliot - 04-Physical Exam\n",
      "Marty Elliot - 03-History Marty\n",
      "Marty Elliot - 05-Patient Satis\n",
      "Marty Elliot - 01-Patient-Physi\n",
      "Marty Elliot - 02-ACIR\n",
      "Marty Elliot - Patient Note Sco\n",
      "Sam Swift (child) Kris Swift (g\n",
      "Sam Swift (child) Kris Swi (1)\n",
      "Sam Swift (child) Kris Swi (2)\n",
      "Sam Swift (child) Kris Swi (3)\n",
      "Sam Swift (child) Kris Swi (4)\n",
      "Sam Swift (child) Kris Swi (5)\n",
      "Shawn Clancy - 05-Patient Satis\n",
      "Shawn Clancy - 01-Patient-Physi\n",
      "Shawn Clancy - 02-ACIR\n",
      "Shawn Clancy - Patient Note Sco\n",
      "Shawn Clancy - 04-Physical Exam\n",
      "Shawn Clancy - 03-History Shawn\n",
      "Tessa Frost - 05-Patient Satisf\n",
      "Tessa Frost - 01-Patient-Physic\n",
      "Tessa Frost - 02-ACIR\n",
      "Tessa Frost - Patient Note Scor\n",
      "Tessa Frost - 04-Physical Exam \n",
      "Tessa Frost - 03-History Tessa \n",
      "[u'Student Name_SP_TW', u'School ID_SP_TW', u'Class Year_SP_TW', u'Patient Name_SP_TW', u'Evaluator Name_SP_TW', u'Exam Date/Time_SP_TW', u'Total_SP_TW', u'Student Name_SP_AMBN', u'School ID_SP_AMBN', u'Class Year_SP_AMBN', u'Patient Name_SP_AMBN', u'Evaluator Name_SP_AMBN', u'Exam Date/Time_SP_AMBN', u'Total_SP_AMBN', u'Q1_PPI_SP_AMBN', u'Q2_PPI_SP_AMBN', u'Q3_PPI_SP_AMBN', u'Q4_PPI_SP_AMBN', u'Q5_PPI_SP_AMBN', u'Q6_PPI_SP_AMBN', u'Q7_PPI_SP_AMBN', u'Q8_PPI_SP_AMBN', u'Q9_PPI_SP_AMBN', u'Q10_PPI_SP_AMBN', u'Q11_PPI_SP_AMBN', u'Q12_PPI_SP_AMBN', u'Total_PPI_SP_AMBN', u'Student Name_SP_WL', u'School ID_SP_WL', u'Class Year_SP_WL', u'Patient Name_SP_WL', u'Evaluator Name_SP_WL', u'Exam Date/Time_SP_WL', u'Total_SP_WL', u'Student Name_SP_SOB', u'School ID_SP_SOB', u'Class Year_SP_SOB', u'Patient Name_SP_SOB', u'Evaluator Name_SP_SOB', u'Exam Date/Time_SP_SOB', u'Total_SP_SOB', u'Student Name_SP_H', u'School ID_SP_H', u'Class Year_SP_H', u'Patient Name_SP_H', u'Evaluator Name_SP_H', u'Exam Date/Time_SP_H', u'Total_SP_H', u'Student Name_SP_CP', u'School ID_SP_CP', u'Class Year_SP_CP', u'Patient Name_SP_CP', u'Evaluator Name_SP_CP', u'Exam Date/Time_SP_CP', u'Total_SP_CP', u'Student Name_SP_AP', u'School ID_SP_AP', u'Class Year_SP_AP', u'Patient Name_SP_AP', u'Evaluator Name_SP_AP', u'Exam Date/Time_SP_AP', u'Total_SP_AP', u'Student Name_SP_CS', u'School ID_SP_CS', u'Class Year_SP_CS', u'Patient Name_SP_CS', u'Evaluator Name_SP_CS', u'Exam Date/Time_SP_CS', u'Total_SP_CS', u'Student Name_SP_KP', u'School ID_SP_KP', u'Class Year_SP_KP', u'Patient Name_SP_KP', u'Evaluator Name_SP_KP', u'Exam Date/Time_SP_KP', u'Total_SP_KP', u'Student Name_SP_LAP', u'School ID_SP_LAP', u'Class Year_SP_LAP', u'Patient Name_SP_LAP', u'Evaluator Name_SP_LAP', u'Exam Date/Time_SP_LAP', u'Total_SP_LAP']\n",
      "Calculating Mean and Variance of Question Groups...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6e0c10cbabc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_dataset_2009\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_clean_year_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2009\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_2009\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_dataset_2009\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclean_dataset_2009\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-0308dd53558b>\u001b[0m in \u001b[0;36mload_and_clean_year_data\u001b[0;34m(year, year_dict)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating Mean and Variance of Question Groups...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mean_var_for_year\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moveralldf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossible_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Deidentifying and adding scores...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d5192b2f9b8f>\u001b[0m in \u001b[0;36mget_mean_var_for_year\u001b[0;34m(yearDF, year_dict, possible_points)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mall_poss_points_for_sub_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_poss_points_for_sub_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mnew_year_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mform_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub_cat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myearDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_questions_for_sub_cat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_poss_points_for_sub_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mnew_year_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"var_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mform_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub_cat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myearDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_questions_for_sub_cat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_poss_points_for_sub_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_combine_series\u001b[0;34m(self, other, func, fill_value, axis, level)\u001b[0m\n\u001b[1;32m   3581\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3582\u001b[0m                 return self._combine_match_columns(other, func, level=level,\n\u001b[0;32m-> 3583\u001b[0;31m                                                    fill_value=fill_value)\n\u001b[0m\u001b[1;32m   3584\u001b[0m         return self._combine_series_infer(other, func, level=level,\n\u001b[1;32m   3585\u001b[0m                                           fill_value=fill_value)\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_combine_match_columns\u001b[0;34m(self, other, func, level, fill_value)\u001b[0m\n\u001b[1;32m   3609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine_match_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3610\u001b[0m         left, right = self.align(other, join='outer', axis=1, level=level,\n\u001b[0;32m-> 3611\u001b[0;31m                                  copy=False)\n\u001b[0m\u001b[1;32m   3612\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m             raise NotImplementedError(\"fill_value %r not supported\" %\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36malign\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m   2814\u001b[0m                                             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m                                             \u001b[0mfill_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2816\u001b[0;31m                                             broadcast_axis=broadcast_axis)\n\u001b[0m\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2818\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reindex'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36malign\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m   4417\u001b[0m                                       \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4418\u001b[0m                                       \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4419\u001b[0;31m                                       fill_axis=fill_axis)\n\u001b[0m\u001b[1;32m   4420\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4421\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unsupported type: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_align_series\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[0m\n\u001b[1;32m   4514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4515\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlidx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4516\u001b[0;31m                     \u001b[0mfdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4517\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4518\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Must specify axis=0 or 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   3837\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3839\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   2492\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2494\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m     def reindex(self, target, method=None, level=None, limit=None,\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "clean_dataset_2009 = load_and_clean_year_data(2009, dict_2009)\n",
    "\n",
    "print(clean_dataset_2009.shape)\n",
    "clean_dataset_2009.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict_2008 = {\n",
    "#     'ppi_initiation': [\"Q1_PPI\", \"Q2_PPI\", \"Q3_PPI\", \"Q4_PPI\"], \n",
    "#     'ppi_info_gather': [\"Q5_PPI\", \"Q6_PPI\", \"Q7_PPI\", \"Q8_PPI\", \"Q9_PPI\", \"Q10_PPI\", \"Q11_PPI\"], \n",
    "#     'ppi_closing': [\"Q12_PPI\", \"Q13_PPI\", \"Q14_PPI\"], \n",
    "#     'hx_physical': [\"Q1_Hx\", \"Q2_Hx\", \"Q3_Hx\", \"Q4_Hx\", \"Q5_Hx\", \"Q6_Hx\", \"Q7_Hx\", \"Q8_Hx\", \"Q9_Hx\", \"Q10_Hx\", \"Q11_Hx\", \"Q12_Hx\"], \n",
    "#     'hx_social': [\"Q13_Hx\"], \n",
    "#     'pe_handwash': [\"Q1_PE\"], \n",
    "#     'pe_phys_check': [\"Q2_PE\", \"Q4_PE\", \"Q5_PE\", \"Q6_PE\", \"Q7_PE\", \"Q8_PE\", \"Q9_PE\", \"Q10_PE\", \"Q11_PE\", \"Q12_PE\", \"Q13_PE\", \"Q14_PE\", \"Q15_PE\", \"Q16_PE\", \"Q17_PE\", \"Q18_PE\", \"Q19_PE\", \"Q20_PE\"], \n",
    "#     'pe_modesty': [\"Q3_PE\"], \n",
    "#     'ps_personal': ['Q1_PS'], \n",
    "#     'ps_rec': ['Q2_PS']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
