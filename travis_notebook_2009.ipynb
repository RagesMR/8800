{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "#### To use this method, two files have to be saved in this direction: \n",
    "\n",
    "##### 1) Question Raw Data, named YYYYData.xls.  The \"Report\" sheet at the end MUST BE DELETED\n",
    "##### 2) All Students, named YYYYStudents.xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(year):\n",
    "    directory = './'+str(year)+'Data.xls'\n",
    "    \n",
    "    \n",
    "    overallDF = pd.DataFrame()\n",
    "    book = xlrd.open_workbook(directory) \n",
    "    num_sheets = len(book.sheets())\n",
    "\n",
    "    sheet_names = book.sheet_names()\n",
    "    sheet_names\n",
    "\n",
    "    #GET ALL STUDENTS TO USE AS THE INDEX\n",
    "    book_students = xlrd.open_workbook('./'+ str(year) + 'Students.xlsx')\n",
    "    all_students = pd.read_excel('./'+ str(year) + 'Students.xlsx', 'Sheet1', header=None).iloc[:,0].tolist()\n",
    "    \n",
    "    possiblePoints = pd.Series() #creating a separate DF for possible points\n",
    "    \n",
    "    for i in range(num_sheets):\n",
    "        this_sheet = sheet_names[i]\n",
    "        df = pd.read_excel(directory, this_sheet)\n",
    "        df.set_index(df.columns[0], inplace=True)\n",
    "        \n",
    "        possible_points_case = df.iloc[0]\n",
    "        possiblePoints = possiblePoints.append(possible_points_case)\n",
    "        \n",
    "        df = df.reindex(all_students)\n",
    "        df = df.reset_index()\n",
    "        overallDF = pd.concat([overallDF, df], axis=1)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    return overallDF, possiblePoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_ID = pd.read_excel('./AllStudentsWithNumbers.xlsx', 'Sheet1')\n",
    "\n",
    "ID_Score = pd.read_excel('./CSResults.xlsx', '2008-2014')\n",
    "\n",
    "name_ID_score = pd.merge(name_ID, ID_Score, on=['Identifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Mean and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize values by dividing by possible points for that question, then compute row-wise mean and variance for those selected columns and add to end of DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mean_var_for_year(yearDF, year_dict, possible_points):\n",
    "    def construct_full_q(q, form_name, case_name):\n",
    "        return q + \"_\" + form_name + \"_SP_\" + case_name\n",
    "    \n",
    "    new_year_df = pd.DataFrame()\n",
    "    new_year_df[\"StudentName\"] = yearDF.iloc[:,0]\n",
    "    \n",
    "    for form_name, sub_cat_dict in year_dict.iteritems():\n",
    "        for sub_cat, case_dict in sub_cat_dict.iteritems():\n",
    "            for case, questions in case_dict.iteritems():\n",
    "                col_names = [construct_full_q(q, form_name, case) for q in questions]\n",
    "                selected_cols = list(yearDF.loc[:, yearDF.columns.str.contains(('|'.join(col_names)))].columns)\n",
    "                selected_points = possible_points[col_names]\n",
    "                new_year_df[\"mean_\" + form_name + \"_\" + sub_cat] = yearDF[selected_cols].div(selected_points).mean(axis=1)\n",
    "                new_year_df[\"var_\" + form_name + \"_\" + sub_cat] = yearDF[selected_cols].div(selected_points).var(axis=1)\n",
    "    \n",
    "    return new_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper method to generate list of strings based on start and end question numbers\n",
    "def generate_question_strings(first_q, last_q):\n",
    "    def question_string(num):\n",
    "        return \"Q\" + str(num)\n",
    "    int_list = list(range(first_q,last_q+1))\n",
    "    return [question_string(num) for num in int_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deidentify_and_add_scores(year_DF, year):\n",
    "    named_ID_score_year = name_ID_score[name_ID_score.Year_x == year]\n",
    "\n",
    "    with_scores = pd.merge(year_DF, named_ID_score_year, left_on = 'StudentName', right_on = 'Student Name')\n",
    "\n",
    "    final_df = with_scores.drop(['StudentName', 'Student Name', 'Year_y'], axis=1)\n",
    "    \n",
    "    ## Move Identifier Column and year to the front of the DF, then rename\n",
    "    cols = list(final_df)\n",
    "    cols.insert(0, cols.pop(cols.index('Identifier')))\n",
    "    cols.insert(1, cols.pop(cols.index('Year_x')))\n",
    "    final_df = final_df.ix[:, cols]\n",
    "    \n",
    "    #Rename some columns\n",
    "    final_df = final_df.rename(index=str, columns={\"Identifier\": \"ID\", \"Year_x\": \"Year\"})\n",
    "    \n",
    "    #Transform scores\n",
    "    final_df['P/F'] = final_df['P/F'].map({'P':1,'F':0})\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_clean_year_data(year, year_dict):\n",
    "    print(\"loading \" + str(year) + \" excel sheet....\")\n",
    "    overalldf, possible_points = load_data(year)\n",
    "    \n",
    "    print(\"Calculating Mean and Variance of Question Groups...\")\n",
    "    modified = get_mean_var_for_year(overalldf, year_dict, possible_points)\n",
    "    \n",
    "    print(\"Deidentifying and adding scores...\")\n",
    "    final_year_df = deidentify_and_add_scores(modified, year)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return final_year_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_2009 = {\n",
    "    'PPI': {\n",
    "        'init': {\n",
    "            'AP': generate_question_strings(1,4),\n",
    "            'TW': generate_question_strings(1,4)\n",
    "        },\n",
    "        'info_gather': {\n",
    "            'AP': generate_question_strings(5,12),\n",
    "            'TW': generate_question_strings(5,12)\n",
    "        },\n",
    "        'closing': {\n",
    "            'AP': generate_question_strings(13,16),\n",
    "            'TW': generate_question_strings(13,16)\n",
    "        }\n",
    "    },\n",
    "    'Hx': {\n",
    "        'physical': {\n",
    "            'AP': generate_question_strings(1,8),\n",
    "            'TW': generate_question_strings(1,12)\n",
    "        },\n",
    "        'social': {\n",
    "            'AP': generate_question_strings(9,9),\n",
    "            'TW': generate_question_strings(13,13)\n",
    "        }\n",
    "\n",
    "    },\n",
    "    'PE': {\n",
    "        'handwash': {\n",
    "            'AP': generate_question_strings(1,1),\n",
    "            'TW': generate_question_strings(1,1)\n",
    "        },\n",
    "        'phys_check': {\n",
    "            'AP': generate_question_strings(2,2) + generate_question_strings(4,9),\n",
    "            'TW': generate_question_strings(2,2) + generate_question_strings(4,20)\n",
    "        },\n",
    "        'modesty': {\n",
    "            'AP': generate_question_strings(3,3),\n",
    "            'TW': generate_question_strings(3,3)\n",
    "        }\n",
    "    },\n",
    "    'PS': {\n",
    "        'personal': {\n",
    "            'AP': generate_question_strings(1,1),\n",
    "            'TW': generate_question_strings(1,1)\n",
    "        },\n",
    "        'rec': {\n",
    "            'AP': generate_question_strings(2,2),\n",
    "            'TW': generate_question_strings(2,2)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 2009 excel sheet....\n",
      "Calculating Mean and Variance of Question Groups...\n",
      "Deidentifying and adding scores...\n",
      "Done!\n",
      "(109, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>mean_PS_personal</th>\n",
       "      <th>var_PS_personal</th>\n",
       "      <th>mean_PS_rec</th>\n",
       "      <th>var_PS_rec</th>\n",
       "      <th>mean_PPI_info_gather</th>\n",
       "      <th>var_PPI_info_gather</th>\n",
       "      <th>mean_PPI_init</th>\n",
       "      <th>var_PPI_init</th>\n",
       "      <th>...</th>\n",
       "      <th>var_Hx_social</th>\n",
       "      <th>mean_Hx_physical</th>\n",
       "      <th>var_Hx_physical</th>\n",
       "      <th>mean_PE_modesty</th>\n",
       "      <th>var_PE_modesty</th>\n",
       "      <th>mean_PE_handwash</th>\n",
       "      <th>var_PE_handwash</th>\n",
       "      <th>mean_PE_phys_check</th>\n",
       "      <th>var_PE_phys_check</th>\n",
       "      <th>P/F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815893</td>\n",
       "      <td>2009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>792928</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.183007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>662719</td>\n",
       "      <td>2009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>610461</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.261438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624003</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Year  mean_PS_personal  var_PS_personal  mean_PS_rec  var_PS_rec  \\\n",
       "0  815893  2009               NaN              NaN          NaN         NaN   \n",
       "1  792928  2009              0.75              NaN         0.25         NaN   \n",
       "2  662719  2009               NaN              NaN          NaN         NaN   \n",
       "3  610461  2009              1.00              NaN         1.00         NaN   \n",
       "4  624003  2009              1.00              NaN         1.00         NaN   \n",
       "\n",
       "   mean_PPI_info_gather  var_PPI_info_gather  mean_PPI_init  var_PPI_init  \\\n",
       "0                   NaN                  NaN            NaN           NaN   \n",
       "1                 0.875                0.125            1.0           0.0   \n",
       "2                   NaN                  NaN            NaN           NaN   \n",
       "3                 1.000                0.000            1.0           0.0   \n",
       "4                 1.000                0.000            1.0           0.0   \n",
       "\n",
       "  ...   var_Hx_social  mean_Hx_physical  var_Hx_physical  mean_PE_modesty  \\\n",
       "0 ...             NaN               NaN              NaN              NaN   \n",
       "1 ...             NaN          0.666667         0.242424              1.0   \n",
       "2 ...             NaN               NaN              NaN              NaN   \n",
       "3 ...             NaN          0.750000         0.204545              1.0   \n",
       "4 ...             NaN          0.833333         0.151515              1.0   \n",
       "\n",
       "   var_PE_modesty  mean_PE_handwash  var_PE_handwash  mean_PE_phys_check  \\\n",
       "0             NaN               NaN              NaN                 NaN   \n",
       "1             NaN               0.0              NaN            0.222222   \n",
       "2             NaN               NaN              NaN                 NaN   \n",
       "3             NaN               1.0              NaN            0.444444   \n",
       "4             NaN               1.0              NaN            0.500000   \n",
       "\n",
       "   var_PE_phys_check  P/F  \n",
       "0                NaN    1  \n",
       "1           0.183007    1  \n",
       "2                NaN    0  \n",
       "3           0.261438    1  \n",
       "4           0.264706    1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset_2009 = load_and_clean_year_data(2009, dict_2009)\n",
    "\n",
    "print(clean_dataset_2009.shape)\n",
    "clean_dataset_2009.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict_2008 = {\n",
    "#     'ppi_initiation': [\"Q1_PPI\", \"Q2_PPI\", \"Q3_PPI\", \"Q4_PPI\"], \n",
    "#     'ppi_info_gather': [\"Q5_PPI\", \"Q6_PPI\", \"Q7_PPI\", \"Q8_PPI\", \"Q9_PPI\", \"Q10_PPI\", \"Q11_PPI\"], \n",
    "#     'ppi_closing': [\"Q12_PPI\", \"Q13_PPI\", \"Q14_PPI\"], \n",
    "#     'hx_physical': [\"Q1_Hx\", \"Q2_Hx\", \"Q3_Hx\", \"Q4_Hx\", \"Q5_Hx\", \"Q6_Hx\", \"Q7_Hx\", \"Q8_Hx\", \"Q9_Hx\", \"Q10_Hx\", \"Q11_Hx\", \"Q12_Hx\"], \n",
    "#     'hx_social': [\"Q13_Hx\"], \n",
    "#     'pe_handwash': [\"Q1_PE\"], \n",
    "#     'pe_phys_check': [\"Q2_PE\", \"Q4_PE\", \"Q5_PE\", \"Q6_PE\", \"Q7_PE\", \"Q8_PE\", \"Q9_PE\", \"Q10_PE\", \"Q11_PE\", \"Q12_PE\", \"Q13_PE\", \"Q14_PE\", \"Q15_PE\", \"Q16_PE\", \"Q17_PE\", \"Q18_PE\", \"Q19_PE\", \"Q20_PE\"], \n",
    "#     'pe_modesty': [\"Q3_PE\"], \n",
    "#     'ps_personal': ['Q1_PS'], \n",
    "#     'ps_rec': ['Q2_PS']\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
