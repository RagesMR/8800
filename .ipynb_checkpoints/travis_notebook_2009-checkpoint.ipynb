{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "#### To use this method, two files have to be saved in this direction: \n",
    "\n",
    "##### 1) Question Raw Data, named YYYYData.xls.  The \"Report\" sheet at the end MUST BE DELETED\n",
    "##### 2) All Students, named YYYYStudents.xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(year):\n",
    "    directory = './'+str(year)+'Data.xls'\n",
    "    \n",
    "    \n",
    "    overallDF = pd.DataFrame()\n",
    "    book = xlrd.open_workbook(directory) \n",
    "    num_sheets = len(book.sheets())\n",
    "\n",
    "    sheet_names = book.sheet_names()\n",
    "    sheet_names\n",
    "\n",
    "    #GET ALL STUDENTS TO USE AS THE INDEX\n",
    "    book_students = xlrd.open_workbook('./'+ str(year) + 'Students.xlsx')\n",
    "    all_students = pd.read_excel('./'+ str(year) + 'Students.xlsx', 'Sheet1', header=None).iloc[:,0].tolist()\n",
    "    \n",
    "    possiblePoints = pd.Series() #creating a separate DF for possible points\n",
    "    \n",
    "    for i in range(num_sheets):\n",
    "        this_sheet = sheet_names[i]\n",
    "        df = pd.read_excel(directory, this_sheet)\n",
    "        df.set_index(df.columns[0], inplace=True)\n",
    "        \n",
    "        possible_points_case = df.iloc[0]\n",
    "        possiblePoints = possiblePoints.append(possible_points_case)\n",
    "        \n",
    "        df = df.reindex(all_students) #somewhere around here is where you decide what to do with NaN values\n",
    "        df = df.reset_index()\n",
    "        overallDF = pd.concat([overallDF, df], axis=1)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    return overallDF, possiblePoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_ID = pd.read_excel('./AllStudentsWithNumbers.xlsx', 'Sheet1')\n",
    "\n",
    "ID_Score = pd.read_excel('./CSResults.xlsx', '2008-2014')\n",
    "\n",
    "name_ID_score = pd.merge(name_ID, ID_Score, on=['Identifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Mean and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize values by dividing by possible points for that question, then compute row-wise mean and variance for those selected columns and add to end of DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mean_var_for_year(yearDF, year_dict, possible_points):\n",
    "    def construct_full_q(q, form_name, case_name):\n",
    "        return q + \"_\" + form_name + \"_SP_\" + case_name\n",
    "    \n",
    "    new_year_df = pd.DataFrame()\n",
    "    new_year_df[\"StudentName\"] = yearDF.iloc[:,0]\n",
    "    \n",
    "    for form_name, sub_cat_dict in year_dict.iteritems():\n",
    "        for sub_cat, case_dict in sub_cat_dict.iteritems():\n",
    "#             print(sub_cat)\n",
    "            all_questions_for_sub_cat = []\n",
    "            all_poss_points_for_sub_cat = pd.Series()\n",
    "            for case, questions in case_dict.iteritems():\n",
    "#                 print(\".......................\" + case)\n",
    "                col_names = [construct_full_q(q, form_name, case) for q in questions]\n",
    "                selected_cols = list(yearDF.loc[:, yearDF.columns.str.contains(('|'.join(col_names)))].columns)\n",
    "#                 if (case == 'AMBN'):\n",
    "#                     print(\"Questions: \")\n",
    "#                     print(questions)\n",
    "#                     print(\"Column Names For Query:\")\n",
    "#                     print(col_names)\n",
    "#                     print(\"Columns Selected:\")\n",
    "#                     print(selected_cols)\n",
    "#                 print(all_questions_for_sub_cat)\n",
    "                all_questions_for_sub_cat = all_questions_for_sub_cat + selected_cols\n",
    "#                 print(all_questions_for_sub_cat)\n",
    "                selected_points = possible_points[col_names]\n",
    "#                 print(type(selected_points))\n",
    "                all_poss_points_for_sub_cat = all_poss_points_for_sub_cat.append(selected_points) \n",
    "#             print(\"Qs: \")\n",
    "#             print(len(all_questions_for_sub_cat))\n",
    "#             print(\"Poss Points\")\n",
    "#             print(all_poss_points_for_sub_cat.shape)\n",
    "#             print(\"mean_\" + form_name + \"_\" + sub_cat)\n",
    "\n",
    "#             if(len(all_questions_for_sub_cat) != len(set(all_questions_for_sub_cat))):\n",
    "#                 seen = {}\n",
    "#                 dupes = []\n",
    "\n",
    "#                 for x in all_questions_for_sub_cat:\n",
    "#                     if x not in seen:\n",
    "#                         seen[x] = 1\n",
    "#                     else:\n",
    "#                         if seen[x] == 1:\n",
    "#                             dupes.append(x)\n",
    "#                         seen[x] += 1\n",
    "#                 print(dupes)\n",
    "#             yearDF[all_questions_for_sub_cat].div(all_poss_points_for_sub_cat).mean(axis=1)\n",
    "#             print(\"Made it\")\n",
    "            new_year_df[\"mean_\" + form_name + \"_\" + sub_cat] = yearDF[all_questions_for_sub_cat].div(all_poss_points_for_sub_cat).mean(axis=1)\n",
    "            new_year_df[\"var_\" + form_name + \"_\" + sub_cat] = yearDF[all_questions_for_sub_cat].div(all_poss_points_for_sub_cat).var(axis=1)\n",
    "    \n",
    "    return new_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper method to generate list of strings based on start and end question numbers\n",
    "def generate_question_strings(first_q, last_q):\n",
    "    def question_string(num):\n",
    "        return \"Q\" + str(num)\n",
    "    int_list = list(range(first_q,last_q+1))\n",
    "    return [question_string(num) for num in int_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deidentify_and_add_scores(year_DF, year):\n",
    "    named_ID_score_year = name_ID_score[name_ID_score.Year_x == year]\n",
    "\n",
    "    with_scores = pd.merge(year_DF, named_ID_score_year, left_on = 'StudentName', right_on = 'Student Name')\n",
    "\n",
    "    final_df = with_scores.drop(['StudentName', 'Student Name', 'Year_y'], axis=1)\n",
    "    \n",
    "    ## Move Identifier Column and year to the front of the DF, then rename\n",
    "    cols = list(final_df)\n",
    "    cols.insert(0, cols.pop(cols.index('Identifier')))\n",
    "    cols.insert(1, cols.pop(cols.index('Year_x')))\n",
    "    final_df = final_df.ix[:, cols]\n",
    "    \n",
    "    #Rename some columns\n",
    "    final_df = final_df.rename(index=str, columns={\"Identifier\": \"ID\", \"Year_x\": \"Year\"})\n",
    "    \n",
    "    #Transform scores\n",
    "    final_df['P/F'] = final_df['P/F'].map({'P':1,'F':0})\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_clean_year_data(year, year_dict):\n",
    "    print(\"loading \" + str(year) + \" excel sheet....\")\n",
    "    overalldf, possible_points = load_data(year)\n",
    "    \n",
    "    seen = {}\n",
    "    dupes = []\n",
    "\n",
    "    for x in overalldf.columns:\n",
    "        if x not in seen:\n",
    "            seen[x] = 1\n",
    "        else:\n",
    "            if seen[x] == 1:\n",
    "                dupes.append(x)\n",
    "            seen[x] += 1\n",
    "    print(dupes)\n",
    "    \n",
    "    print(\"Calculating Mean and Variance of Question Groups...\")\n",
    "    modified = get_mean_var_for_year(overalldf, year_dict, possible_points)\n",
    "    \n",
    "    print(\"Deidentifying and adding scores...\")\n",
    "    final_year_df = deidentify_and_add_scores(modified, year)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return final_year_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_2009 = {\n",
    "    'PPI': {\n",
    "        'init': {\n",
    "            'AP': generate_question_strings(1,4), #Marty Elliot\n",
    "            'TW': generate_question_strings(1,4), #Alex Miller\n",
    "            'AMBN': generate_question_strings(1,4), #Carol Whitman\n",
    "            'WL': generate_question_strings(1,4), #Corey Wolfe\n",
    "            'SOB': generate_question_strings(1,4), #Dana Mitchell\n",
    "            'H': generate_question_strings(1,3),  #Jamie Browning\n",
    "            'CP': generate_question_strings(1,4), #Leslie Keats\n",
    "            'CS': generate_question_strings(1,4), #Sam Swift/Grandparent\n",
    "            'KP': generate_question_strings(1,4), #Shawn Clancy\n",
    "            'LAP': generate_question_strings(1,4) #Tessa Frost\n",
    "        },\n",
    "        'info_gather': {\n",
    "            'AP': generate_question_strings(5,12),\n",
    "            'TW': generate_question_strings(5,12),\n",
    "            'AMBN': generate_question_strings(5,12),\n",
    "            'WL': generate_question_strings(5,12),\n",
    "            'SOB': generate_question_strings(5,12),\n",
    "            'H': generate_question_strings(4,11),\n",
    "            'CP': generate_question_strings(5,12),\n",
    "            'CS': generate_question_strings(5,12),\n",
    "            'KP': generate_question_strings(5,12),\n",
    "            'LAP': generate_question_strings(5,12) \n",
    "        },\n",
    "        'closing': {\n",
    "            'AP': generate_question_strings(13,16),\n",
    "            'TW': generate_question_strings(13,16),\n",
    "            'AMBN': generate_question_strings(13,16),\n",
    "            'WL': generate_question_strings(13,16),\n",
    "            'SOB': generate_question_strings(13,16),\n",
    "            'H': generate_question_strings(12,15),\n",
    "            'CP': generate_question_strings(13,16),\n",
    "            'CS': generate_question_strings(13,16),\n",
    "            'KP': generate_question_strings(13,16),\n",
    "            'LAP': generate_question_strings(13,16)\n",
    "        }\n",
    "    },\n",
    "    'Hx': {\n",
    "        'history': {\n",
    "            'AP': generate_question_strings(1,9),\n",
    "            'TW': generate_question_strings(1,13),\n",
    "            'AMBN': generate_question_strings(1,6),\n",
    "            'WL': generate_question_strings(1,9),\n",
    "            'SOB': generate_question_strings(1,14),\n",
    "            'H': generate_question_strings(1,11),\n",
    "            'CP': generate_question_strings(1,14),\n",
    "            'CS': generate_question_strings(1,11),\n",
    "            'KP': generate_question_strings(1,9),\n",
    "            'LAP': generate_question_strings(1,15)\n",
    "        }\n",
    "    },\n",
    "    'PE': { #Carol Whitman did not do PE\n",
    "        'handwash': {\n",
    "            'AP': generate_question_strings(1,1),\n",
    "            'TW': generate_question_strings(1,1),\n",
    "            'WL': generate_question_strings(1,1),\n",
    "            'SOB': generate_question_strings(1,1),\n",
    "            'H': generate_question_strings(1,1),\n",
    "            'CP': generate_question_strings(1,1),\n",
    "            'CS': generate_question_strings(1,1),\n",
    "            'KP': generate_question_strings(1,1),\n",
    "            'LAP': generate_question_strings(1,1)\n",
    "        },\n",
    "        'phys_check': {\n",
    "            'AP': generate_question_strings(2,2) + generate_question_strings(4,9),\n",
    "            'TW': generate_question_strings(2,2) + generate_question_strings(4,20),\n",
    "            'WL': generate_question_strings(2,2) + generate_question_strings(4,10),\n",
    "            'SOB': generate_question_strings(2,2) + generate_question_strings(4,6),\n",
    "            'H': generate_question_strings(2,2) + generate_question_strings(4,21),\n",
    "            'CP': generate_question_strings(2,2) + generate_question_strings(4,10),\n",
    "            'CS': generate_question_strings(2,2) + generate_question_strings(4,13),\n",
    "            'KP': generate_question_strings(2,2) + generate_question_strings(4,8),\n",
    "            'LAP': generate_question_strings(2,2) + generate_question_strings(3,7)\n",
    "        },\n",
    "        'modesty': {\n",
    "            'AP': generate_question_strings(3,3),\n",
    "            'TW': generate_question_strings(3,3),\n",
    "            'WL': generate_question_strings(3,3),\n",
    "            'SOB': generate_question_strings(3,3),\n",
    "            'H': generate_question_strings(3,3),\n",
    "            'CP': generate_question_strings(3,3),\n",
    "            'CS': generate_question_strings(3,3),\n",
    "            'KP': generate_question_strings(3,3),\n",
    "            'LAP': generate_question_strings(3,3)\n",
    "        }\n",
    "    },\n",
    "    'PS': {\n",
    "        'personal': {\n",
    "            'AP': generate_question_strings(1,1),\n",
    "            'TW': generate_question_strings(1,1),\n",
    "            'AMBN': generate_question_strings(1,1),\n",
    "            'WL': generate_question_strings(1,1),\n",
    "            'SOB': generate_question_strings(1,1),\n",
    "            'H': generate_question_strings(1,1),\n",
    "            'CP': generate_question_strings(1,1),\n",
    "            'CS': generate_question_strings(1,1),\n",
    "            'KP': generate_question_strings(1,1),\n",
    "            'LAP': generate_question_strings(1,1)\n",
    "        },\n",
    "        'rec': {\n",
    "            'AP': generate_question_strings(2,2),\n",
    "            'TW': generate_question_strings(2,2),\n",
    "            'AMBN': generate_question_strings(2,2),\n",
    "            'WL': generate_question_strings(2,2),\n",
    "            'SOB': generate_question_strings(2,2),\n",
    "            'H': generate_question_strings(2,2),\n",
    "            'CP': generate_question_strings(2,2),\n",
    "            'CS': generate_question_strings(2,2),\n",
    "            'KP': generate_question_strings(2,2),\n",
    "            'LAP': generate_question_strings(1,1)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 2009 excel sheet....\n",
      "Calculating Mean and Variance of Question Groups...\n",
      "Questions: \n",
      "['Q1']\n",
      "Column Names For Query:\n",
      "['Q1_PS_SP_AMBN']\n",
      "Columns Selected:\n",
      "[u'Q1_PS_SP_AMBN']\n",
      "mean_PS_personal\n",
      "Made it\n",
      "Questions: \n",
      "['Q2']\n",
      "Column Names For Query:\n",
      "['Q2_PS_SP_AMBN']\n",
      "Columns Selected:\n",
      "[u'Q2_PS_SP_AMBN']\n",
      "mean_PS_rec\n",
      "Made it\n",
      "Questions: \n",
      "['Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12']\n",
      "Column Names For Query:\n",
      "['Q5_PPI_SP_AMBN', 'Q6_PPI_SP_AMBN', 'Q7_PPI_SP_AMBN', 'Q8_PPI_SP_AMBN', 'Q9_PPI_SP_AMBN', 'Q10_PPI_SP_AMBN', 'Q11_PPI_SP_AMBN', 'Q12_PPI_SP_AMBN']\n",
      "Columns Selected:\n",
      "[u'Q5_PPI_SP_AMBN', u'Q6_PPI_SP_AMBN', u'Q7_PPI_SP_AMBN', u'Q8_PPI_SP_AMBN', u'Q9_PPI_SP_AMBN', u'Q10_PPI_SP_AMBN', u'Q11_PPI_SP_AMBN', u'Q12_PPI_SP_AMBN', u'Q5_PPI_SP_AMBN', u'Q6_PPI_SP_AMBN', u'Q7_PPI_SP_AMBN', u'Q8_PPI_SP_AMBN', u'Q9_PPI_SP_AMBN', u'Q10_PPI_SP_AMBN', u'Q11_PPI_SP_AMBN', u'Q12_PPI_SP_AMBN']\n",
      "mean_PPI_info_gather\n",
      "[u'Q5_PPI_SP_AMBN', u'Q6_PPI_SP_AMBN', u'Q7_PPI_SP_AMBN', u'Q8_PPI_SP_AMBN', u'Q9_PPI_SP_AMBN', u'Q10_PPI_SP_AMBN', u'Q11_PPI_SP_AMBN', u'Q12_PPI_SP_AMBN']\n",
      "Made it\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-6e0c10cbabc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_dataset_2009\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_clean_year_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2009\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_2009\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_dataset_2009\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclean_dataset_2009\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-a7c6108c1bac>\u001b[0m in \u001b[0;36mload_and_clean_year_data\u001b[0;34m(year, year_dict)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating Mean and Variance of Question Groups...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mean_var_for_year\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moveralldf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossible_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Deidentifying and adding scores...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-ebe4b4e11344>\u001b[0m in \u001b[0;36mget_mean_var_for_year\u001b[0;34m(yearDF, year_dict, possible_points)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#             yearDF[all_questions_for_sub_cat].div(all_poss_points_for_sub_cat).mean(axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Made it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mnew_year_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mform_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub_cat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myearDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_questions_for_sub_cat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_poss_points_for_sub_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mnew_year_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"var_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mform_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub_cat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myearDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_questions_for_sub_cat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_poss_points_for_sub_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_combine_series\u001b[0;34m(self, other, func, fill_value, axis, level)\u001b[0m\n\u001b[1;32m   3581\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3582\u001b[0m                 return self._combine_match_columns(other, func, level=level,\n\u001b[0;32m-> 3583\u001b[0;31m                                                    fill_value=fill_value)\n\u001b[0m\u001b[1;32m   3584\u001b[0m         return self._combine_series_infer(other, func, level=level,\n\u001b[1;32m   3585\u001b[0m                                           fill_value=fill_value)\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_combine_match_columns\u001b[0;34m(self, other, func, level, fill_value)\u001b[0m\n\u001b[1;32m   3609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine_match_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3610\u001b[0m         left, right = self.align(other, join='outer', axis=1, level=level,\n\u001b[0;32m-> 3611\u001b[0;31m                                  copy=False)\n\u001b[0m\u001b[1;32m   3612\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m             raise NotImplementedError(\"fill_value %r not supported\" %\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36malign\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m   2814\u001b[0m                                             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m                                             \u001b[0mfill_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2816\u001b[0;31m                                             broadcast_axis=broadcast_axis)\n\u001b[0m\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2818\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reindex'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36malign\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m   4417\u001b[0m                                       \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4418\u001b[0m                                       \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4419\u001b[0;31m                                       fill_axis=fill_axis)\n\u001b[0m\u001b[1;32m   4420\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4421\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unsupported type: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_align_series\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[0m\n\u001b[1;32m   4514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4515\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlidx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4516\u001b[0;31m                     \u001b[0mfdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4517\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4518\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Must specify axis=0 or 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   3837\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3839\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   2492\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2494\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m     def reindex(self, target, method=None, level=None, limit=None,\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "clean_dataset_2009 = load_and_clean_year_data(2009, dict_2009)\n",
    "\n",
    "print(clean_dataset_2009.shape)\n",
    "clean_dataset_2009.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict_2008 = {\n",
    "#     'ppi_initiation': [\"Q1_PPI\", \"Q2_PPI\", \"Q3_PPI\", \"Q4_PPI\"], \n",
    "#     'ppi_info_gather': [\"Q5_PPI\", \"Q6_PPI\", \"Q7_PPI\", \"Q8_PPI\", \"Q9_PPI\", \"Q10_PPI\", \"Q11_PPI\"], \n",
    "#     'ppi_closing': [\"Q12_PPI\", \"Q13_PPI\", \"Q14_PPI\"], \n",
    "#     'hx_physical': [\"Q1_Hx\", \"Q2_Hx\", \"Q3_Hx\", \"Q4_Hx\", \"Q5_Hx\", \"Q6_Hx\", \"Q7_Hx\", \"Q8_Hx\", \"Q9_Hx\", \"Q10_Hx\", \"Q11_Hx\", \"Q12_Hx\"], \n",
    "#     'hx_social': [\"Q13_Hx\"], \n",
    "#     'pe_handwash': [\"Q1_PE\"], \n",
    "#     'pe_phys_check': [\"Q2_PE\", \"Q4_PE\", \"Q5_PE\", \"Q6_PE\", \"Q7_PE\", \"Q8_PE\", \"Q9_PE\", \"Q10_PE\", \"Q11_PE\", \"Q12_PE\", \"Q13_PE\", \"Q14_PE\", \"Q15_PE\", \"Q16_PE\", \"Q17_PE\", \"Q18_PE\", \"Q19_PE\", \"Q20_PE\"], \n",
    "#     'pe_modesty': [\"Q3_PE\"], \n",
    "#     'ps_personal': ['Q1_PS'], \n",
    "#     'ps_rec': ['Q2_PS']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
